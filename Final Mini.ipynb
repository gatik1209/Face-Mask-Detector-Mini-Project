{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fd942e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] starting video stream...\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "from imutils.video import VideoStream\n",
    "import numpy as np\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def detect_and_predict_mask(frame, faceNet, maskNet):\n",
    "\t# grab the dimensions of the frame and then construct a blob\n",
    "\t# from it\n",
    "\t(h, w) = frame.shape[:2]\n",
    "\tblob = cv2.dnn.blobFromImage(frame, 1.0, (224, 224),\n",
    "\t\t(104.0, 177.0, 123.0))\n",
    "\n",
    "\t# pass the blob through the network and obtain the face detections\n",
    "\tfaceNet.setInput(blob)\n",
    "\tdetections = faceNet.forward()\n",
    "\tprint(detections.shape)\n",
    "\n",
    "\t# initialize our list of faces, their corresponding locations,\n",
    "\t# and the list of predictions from our face mask network\n",
    "\tfaces = []\n",
    "\tlocs = []\n",
    "\tpreds = []\n",
    "\n",
    "\t# loop over the detections\n",
    "\tfor i in range(0, detections.shape[2]):\n",
    "\t\t# extract the confidence (i.e., probability) associated with\n",
    "\t\t# the detection\n",
    "\t\tconfidence = detections[0, 0, i, 2]\n",
    "\n",
    "\t\t# filter out weak detections by ensuring the confidence is\n",
    "\t\t# greater than the minimum confidence\n",
    "\t\tif confidence > 0.5:\n",
    "\t\t\t# compute the (x, y)-coordinates of the bounding box for\n",
    "\t\t\t# the object\n",
    "\t\t\tbox = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "\t\t\t(startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "\t\t\t# ensure the bounding boxes fall within the dimensions of\n",
    "\t\t\t# the frame\n",
    "\t\t\t(startX, startY) = (max(0, startX), max(0, startY))\n",
    "\t\t\t(endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n",
    "\n",
    "\t\t\t# extract the face ROI, convert it from BGR to RGB channel\n",
    "\t\t\t# ordering, resize it to 224x224, and preprocess it\n",
    "\t\t\tface = frame[startY:endY, startX:endX]\n",
    "\t\t\tface = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "\t\t\tface = cv2.resize(face, (224, 224))\n",
    "\t\t\tface = img_to_array(face)\n",
    "\t\t\tface = preprocess_input(face)\n",
    "\n",
    "\t\t\t# add the face and bounding boxes to their respective\n",
    "\t\t\t# lists\n",
    "\t\t\tfaces.append(face)\n",
    "\t\t\tlocs.append((startX, startY, endX, endY))\n",
    "\n",
    "\t# only make a predictions if at least one face was detected\n",
    "\tif len(faces) > 0:\n",
    "\t\t# for faster inference we'll make batch predictions on *all*\n",
    "\t\t# faces at the same time rather than one-by-one predictions\n",
    "\t\t# in the above `for` loop\n",
    "\t\tfaces = np.array(faces, dtype=\"float32\")\n",
    "\t\tpreds = maskNet.predict(faces, batch_size=32)\n",
    "\n",
    "\t# return a 2-tuple of the face locations and their corresponding\n",
    "\t# locations\n",
    "\treturn (locs, preds)\n",
    "\n",
    "# load our serialized face detector model from disk\n",
    "prototxtPath = r\"face_detector\\deploy.prototxt\"\n",
    "weightsPath = r\"face_detector\\res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "faceNet = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
    "\n",
    "# load the face mask detector model from disk\n",
    "maskNet = load_model(\"mask_detector.model\")\n",
    "\n",
    "# initialize the video stream\n",
    "print(\"[INFO] starting video stream...\")\n",
    "vs = VideoStream(src=0).start()\n",
    "\n",
    "# loop over the frames from the video stream\n",
    "while True:\n",
    "\t# grab the frame from the threaded video stream and resize it\n",
    "\t# to have a maximum width of 400 pixels\n",
    "\tframe = vs.read()\n",
    "\tframe = imutils.resize(frame, width=400)\n",
    "\n",
    "\t# detect faces in the frame and determine if they are wearing a\n",
    "\t# face mask or not\n",
    "\t(locs, preds) = detect_and_predict_mask(frame, faceNet, maskNet)\n",
    "\n",
    "\t# loop over the detected face locations and their corresponding\n",
    "\t# locations\n",
    "\tfor (box, pred) in zip(locs, preds):\n",
    "\t\t# unpack the bounding box and predictions\n",
    "\t\t(startX, startY, endX, endY) = box\n",
    "\t\t(mask, withoutMask) = pred\n",
    "\n",
    "\t\t# determine the class label and color we'll use to draw\n",
    "\t\t# the bounding box and text\n",
    "\t\tlabel = \"Mask\" if mask > withoutMask else \"No Mask\"\n",
    "\t\tcolor = (0, 255, 0) if label == \"Mask\" else (0, 0, 255)\n",
    "\n",
    "\t\t# include the probability in the label\n",
    "\t\tlabel = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
    "\n",
    "\t\t# display the label and bounding box rectangle on the output\n",
    "\t\t# frame\n",
    "\t\tcv2.putText(frame, label, (startX, startY - 10),\n",
    "\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
    "\t\tcv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\n",
    "\n",
    "\t# show the output frame\n",
    "\tcv2.imshow(\"Frame\", frame)\n",
    "\tkey = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "\t# if the `q` key was pressed, break from the loop\n",
    "\tif key == ord(\"q\"):\n",
    "\t\tbreak\n",
    "\n",
    "# do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e97fe153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.5.0rc3-cp39-cp39-win_amd64.whl (422.6 MB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting numpy~=1.19.2\n",
      "  Downloading numpy-1.19.5-cp39-cp39-win_amd64.whl (13.3 MB)\n",
      "Collecting tensorboard~=2.5Note: you may need to restart the kernel to use updated packages.\n",
      "  Downloading tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting protobuf>=3.9.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading protobuf-3.16.0-py2.py3-none-any.whl (173 kB)\n",
      "Collecting typing-extensions~=3.7.4\n",
      "  Using cached typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting wheel~=0.35\n",
      "  Using cached wheel-0.36.2-py2.py3-none-any.whl (35 kB)\n",
      "Collecting grpcio~=1.34.0\n",
      "  Downloading grpcio-1.34.1-cp39-cp39-win_amd64.whl (2.9 MB)\n",
      "Collecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp39-cp39-win_amd64.whl (2.7 MB)\n",
      "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
      "  Downloading tensorflow_estimator-2.5.0rc0-py2.py3-none-any.whl (462 kB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.12.0-py3-none-any.whl (129 kB)\n",
      "Collecting keras-nightly~=2.5.0.dev\n",
      "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Using cached wrapt-1.12.1.tar.gz (27 kB)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (49.2.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.4-py2.py3-none-any.whl (18 kB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Using cached Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.30.0-py2.py3-none-any.whl (146 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2020.12.5-py2.py3-none-any.whl (147 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Using cached idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.4-py2.py3-none-any.whl (153 kB)\n",
      "Collecting chardet<5,>=3.0.2\n",
      "  Using cached chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Using legacy 'setup.py install' for termcolor, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for wrapt, since package 'wheel' is not installed.\n",
      "Installing collected packages: flatbuffers, numpy, opt-einsum, termcolor, absl-py, certifi, idna, urllib3, chardet, requests, oauthlib, requests-oauthlib, pyasn1, rsa, cachetools, pyasn1-modules, google-auth, google-auth-oauthlib, protobuf, tensorboard-plugin-wit, wheel, werkzeug, markdown, tensorboard-data-server, grpcio, tensorboard, google-pasta, keras-preprocessing, typing-extensions, gast, h5py, tensorflow-estimator, astunparse, keras-nightly, wrapt, tensorflow\n",
      "    Running setup.py install for termcolor: started\n",
      "    Running setup.py install for termcolor: finished with status 'done'\n",
      "    Running setup.py install for wrapt: started\n",
      "    Running setup.py install for wrapt: finished with status 'done'\n",
      "Successfully installed absl-py-0.12.0 astunparse-1.6.3 cachetools-4.2.2 certifi-2020.12.5 chardet-4.0.0 flatbuffers-1.12 gast-0.4.0 google-auth-1.30.0 google-auth-oauthlib-0.4.4 google-pasta-0.2.0 grpcio-1.34.1 h5py-3.1.0 idna-2.10 keras-nightly-2.5.0.dev2021032900 keras-preprocessing-1.1.2 markdown-3.3.4 numpy-1.19.5 oauthlib-3.1.0 opt-einsum-3.3.0 protobuf-3.16.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.25.1 requests-oauthlib-1.3.0 rsa-4.7.2 tensorboard-2.5.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.5.0rc3 tensorflow-estimator-2.5.0rc0 termcolor-1.1.0 typing-extensions-3.7.4.3 urllib3-1.26.4 werkzeug-1.0.1 wheel-0.36.2 wrapt-1.12.1\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dc4755c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Collecting scipy>=0.14\n",
      "  Downloading scipy-1.6.3-cp39-cp39-win_amd64.whl (32.7 MB)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from keras) (1.19.5)\n",
      "Requirement already satisfied: h5py in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from keras) (3.1.0)\n",
      "Collecting pyyaml\n",
      "  Downloading PyYAML-5.4.1-cp39-cp39-win_amd64.whl (213 kB)\n",
      "Installing collected packages: scipy, pyyaml, keras\n",
      "Successfully installed keras-2.4.3 pyyaml-5.4.1 scipy-1.6.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7984e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imutilsNote: you may need to restart the kernel to use updated packages.\n",
      "  Downloading imutils-0.5.4.tar.gz (17 kB)\n",
      "Building wheels for collected packages: imutils\n",
      "  Building wheel for imutils (setup.py): started\n",
      "  Building wheel for imutils (setup.py): finished with status 'done'\n",
      "  Created wheel for imutils: filename=imutils-0.5.4-py3-none-any.whl size=25860 sha256=44badfe645721a4f4da639ec3c920fe4c1d12bfa14e24aac193c4777dee3fe58\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\4b\\a5\\2d\\4a070a801d3a3d93f033d3ee9728f470f514826e89952df3ea\n",
      "Successfully built imutils\n",
      "Installing collected packages: imutils\n",
      "Successfully installed imutils-0.5.4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install imutils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "247bc252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.2.52-cp39-cp39-win_amd64.whl (34.7 MB)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from opencv-python) (1.19.5)\n",
      "Installing collected packages: opencv-pythonNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 21.1.1 is available."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully installed opencv-python-4.5.2.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "You should consider upgrading via the 'c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe9daa6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.19.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e2e2bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.4.2-cp39-cp39-win_amd64.whl (7.1 MB)\n",
      "Requirement already satisfied: numpy>=1.16 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-8.2.0-cp39-cp39-win_amd64.whl (2.2 MB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.1-cp39-cp39-win_amd64.whl (51 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.Installing collected packages: cycler, pillow, kiwisolver, matplotlib\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.3.1 matplotlib-3.4.2 pillow-8.2.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96f6d688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.6.3)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scipy) (1.19.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01f36782",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "from imutils.video import VideoStream\n",
    "import numpy as np\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f104d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] starting video stream...\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n"
     ]
    }
   ],
   "source": [
    "def detect_and_predict_mask(frame, faceNet, maskNet):\n",
    "\t# grab the dimensions of the frame and then construct a blob\n",
    "\t# from it\n",
    "\t(h, w) = frame.shape[:2]\n",
    "\tblob = cv2.dnn.blobFromImage(frame, 1.0, (224, 224),\n",
    "\t\t(104.0, 177.0, 123.0))\n",
    "\n",
    "\t# pass the blob through the network and obtain the face detections\n",
    "\tfaceNet.setInput(blob)\n",
    "\tdetections = faceNet.forward()\n",
    "\tprint(detections.shape)\n",
    "\n",
    "\t# initialize our list of faces, their corresponding locations,\n",
    "\t# and the list of predictions from our face mask network\n",
    "\tfaces = []\n",
    "\tlocs = []\n",
    "\tpreds = []\n",
    "\n",
    "\t# loop over the detections\n",
    "\tfor i in range(0, detections.shape[2]):\n",
    "\t\t# extract the confidence (i.e., probability) associated with\n",
    "\t\t# the detection\n",
    "\t\tconfidence = detections[0, 0, i, 2]\n",
    "\n",
    "\t\t# filter out weak detections by ensuring the confidence is\n",
    "\t\t# greater than the minimum confidence\n",
    "\t\tif confidence > 0.5:\n",
    "\t\t\t# compute the (x, y)-coordinates of the bounding box for\n",
    "\t\t\t# the object\n",
    "\t\t\tbox = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "\t\t\t(startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "\t\t\t# ensure the bounding boxes fall within the dimensions of\n",
    "\t\t\t# the frame\n",
    "\t\t\t(startX, startY) = (max(0, startX), max(0, startY))\n",
    "\t\t\t(endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n",
    "\n",
    "\t\t\t# extract the face ROI, convert it from BGR to RGB channel\n",
    "\t\t\t# ordering, resize it to 224x224, and preprocess it\n",
    "\t\t\tface = frame[startY:endY, startX:endX]\n",
    "\t\t\tface = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "\t\t\tface = cv2.resize(face, (224, 224))\n",
    "\t\t\tface = img_to_array(face)\n",
    "\t\t\tface = preprocess_input(face)\n",
    "\n",
    "\t\t\t# add the face and bounding boxes to their respective\n",
    "\t\t\t# lists\n",
    "\t\t\tfaces.append(face)\n",
    "\t\t\tlocs.append((startX, startY, endX, endY))\n",
    "\n",
    "\t# only make a predictions if at least one face was detected\n",
    "\tif len(faces) > 0:\n",
    "\t\t# for faster inference we'll make batch predictions on *all*\n",
    "\t\t# faces at the same time rather than one-by-one predictions\n",
    "\t\t# in the above `for` loop\n",
    "\t\tfaces = np.array(faces, dtype=\"float32\")\n",
    "\t\tpreds = maskNet.predict(faces, batch_size=32)\n",
    "\n",
    "\t# return a 2-tuple of the face locations and their corresponding\n",
    "\t# locations\n",
    "\treturn (locs, preds)\n",
    "\n",
    "# load our serialized face detector model from disk\n",
    "prototxtPath = r\"face_detector\\deploy.prototxt\"\n",
    "weightsPath = r\"face_detector\\res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "faceNet = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
    "\n",
    "# load the face mask detector model from disk\n",
    "maskNet = load_model(\"mask_detector.model\")\n",
    "\n",
    "# initialize the video stream\n",
    "print(\"[INFO] starting video stream...\")\n",
    "vs = VideoStream(src=0).start()\n",
    "\n",
    "# loop over the frames from the video stream\n",
    "while True:\n",
    "\t# grab the frame from the threaded video stream and resize it\n",
    "\t# to have a maximum width of 400 pixels\n",
    "\tframe = vs.read()\n",
    "\tframe = imutils.resize(frame, width=400)\n",
    "\n",
    "\t# detect faces in the frame and determine if they are wearing a\n",
    "\t# face mask or not\n",
    "\t(locs, preds) = detect_and_predict_mask(frame, faceNet, maskNet)\n",
    "\n",
    "\t# loop over the detected face locations and their corresponding\n",
    "\t# locations\n",
    "\tfor (box, pred) in zip(locs, preds):\n",
    "\t\t# unpack the bounding box and predictions\n",
    "\t\t(startX, startY, endX, endY) = box\n",
    "\t\t(mask, withoutMask) = pred\n",
    "\n",
    "\t\t# determine the class label and color we'll use to draw\n",
    "\t\t# the bounding box and text\n",
    "\t\tlabel = \"Mask\" if mask > withoutMask else \"No Mask\"\n",
    "\t\tcolor = (0, 255, 0) if label == \"Mask\" else (0, 0, 255)\n",
    "\n",
    "\t\t# include the probability in the label\n",
    "\t\tlabel = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
    "\n",
    "\t\t# display the label and bounding box rectangle on the output\n",
    "\t\t# frame\n",
    "\t\tcv2.putText(frame, label, (startX, startY - 10),\n",
    "\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
    "\t\tcv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\n",
    "\n",
    "\t# show the output frame\n",
    "\tcv2.imshow(\"Frame\", frame)\n",
    "\tkey = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "\t# if the `q` key was pressed, break from the loop\n",
    "\tif key == ord(\"q\"):\n",
    "\t\tbreak\n",
    "\n",
    "# do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a004856f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.24.2-cp39-cp39-win_amd64.whl (6.9 MB)\n",
      "Collecting threadpoolctl>=2.0.0Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.6.3)\n",
      "Collecting joblib>=0.11\n",
      "  Using cached joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1316 sha256=9d0156e031822999e007fbac238bf5ec2722b29490e617422a3a4b4521a8d98f\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\e4\\7b\\98\\b6466d71b8d738a0c547008b9eb39bf8676d1ff6ca4b22af1c\n",
      "Successfully built sklearn\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn, sklearn\n",
      "Successfully installed joblib-1.0.1 scikit-learn-0.24.2 sklearn-0.0 threadpoolctl-2.1.0\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9912f119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\PIL\\Image.py:962: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9412608/9406464 [==============================] - 1s 0us/step\n",
      "[INFO] compiling model...\n",
      "[INFO] training head...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "95/95 [==============================] - 158s 2s/step - loss: 0.4084 - accuracy: 0.8333 - val_loss: 0.1473 - val_accuracy: 0.9739\n",
      "Epoch 2/20\n",
      "95/95 [==============================] - 151s 2s/step - loss: 0.1419 - accuracy: 0.9647 - val_loss: 0.0804 - val_accuracy: 0.9804\n",
      "Epoch 3/20\n",
      "95/95 [==============================] - 127s 1s/step - loss: 0.0931 - accuracy: 0.9750 - val_loss: 0.0596 - val_accuracy: 0.9870\n",
      "Epoch 4/20\n",
      "95/95 [==============================] - 146s 2s/step - loss: 0.0709 - accuracy: 0.9806 - val_loss: 0.0517 - val_accuracy: 0.9883\n",
      "Epoch 5/20\n",
      "95/95 [==============================] - 141s 1s/step - loss: 0.0622 - accuracy: 0.9815 - val_loss: 0.0459 - val_accuracy: 0.9909\n",
      "Epoch 6/20\n",
      "95/95 [==============================] - 114s 1s/step - loss: 0.0532 - accuracy: 0.9842 - val_loss: 0.0415 - val_accuracy: 0.9909\n",
      "Epoch 7/20\n",
      "95/95 [==============================] - 114s 1s/step - loss: 0.0530 - accuracy: 0.9835 - val_loss: 0.0399 - val_accuracy: 0.9896\n",
      "Epoch 8/20\n",
      "95/95 [==============================] - 135s 1s/step - loss: 0.0467 - accuracy: 0.9858 - val_loss: 0.0369 - val_accuracy: 0.9896\n",
      "Epoch 9/20\n",
      "95/95 [==============================] - 120s 1s/step - loss: 0.0458 - accuracy: 0.9878 - val_loss: 0.0386 - val_accuracy: 0.9883\n",
      "Epoch 10/20\n",
      "95/95 [==============================] - 120s 1s/step - loss: 0.0355 - accuracy: 0.9898 - val_loss: 0.0340 - val_accuracy: 0.9922\n",
      "Epoch 11/20\n",
      "95/95 [==============================] - 124s 1s/step - loss: 0.0419 - accuracy: 0.9878 - val_loss: 0.0362 - val_accuracy: 0.9896\n",
      "Epoch 12/20\n",
      "95/95 [==============================] - 122s 1s/step - loss: 0.0381 - accuracy: 0.9878 - val_loss: 0.0338 - val_accuracy: 0.9922\n",
      "Epoch 13/20\n",
      "95/95 [==============================] - 125s 1s/step - loss: 0.0358 - accuracy: 0.9914 - val_loss: 0.0318 - val_accuracy: 0.9922\n",
      "Epoch 14/20\n",
      "95/95 [==============================] - 121s 1s/step - loss: 0.0351 - accuracy: 0.9868 - val_loss: 0.0301 - val_accuracy: 0.9909\n",
      "Epoch 15/20\n",
      "95/95 [==============================] - 124s 1s/step - loss: 0.0274 - accuracy: 0.9924 - val_loss: 0.0306 - val_accuracy: 0.9922\n",
      "Epoch 16/20\n",
      "95/95 [==============================] - 129s 1s/step - loss: 0.0262 - accuracy: 0.9918 - val_loss: 0.0299 - val_accuracy: 0.9922\n",
      "Epoch 17/20\n",
      "95/95 [==============================] - 148s 2s/step - loss: 0.0317 - accuracy: 0.9891 - val_loss: 0.0302 - val_accuracy: 0.9909\n",
      "Epoch 18/20\n",
      "95/95 [==============================] - 151s 2s/step - loss: 0.0270 - accuracy: 0.9928 - val_loss: 0.0309 - val_accuracy: 0.9909\n",
      "Epoch 19/20\n",
      "95/95 [==============================] - 141s 1s/step - loss: 0.0291 - accuracy: 0.9921 - val_loss: 0.0303 - val_accuracy: 0.9922\n",
      "Epoch 20/20\n",
      "95/95 [==============================] - 143s 1s/step - loss: 0.0262 - accuracy: 0.9908 - val_loss: 0.0347 - val_accuracy: 0.9909\n",
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   with_mask       0.99      0.99      0.99       383\n",
      "without_mask       0.99      0.99      0.99       384\n",
      "\n",
      "    accuracy                           0.99       767\n",
      "   macro avg       0.99      0.99      0.99       767\n",
      "weighted avg       0.99      0.99      0.99       767\n",
      "\n",
      "[INFO] saving mask detector model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# initialize the initial learning rate, number of epochs to train for,\n",
    "# and batch size\n",
    "INIT_LR = 1e-4\n",
    "EPOCHS = 20\n",
    "BS = 32\n",
    "\n",
    "DIRECTORY = r\"E:\\Face-Mask-Detection\\dataset\"\n",
    "CATEGORIES = [\"with_mask\", \"without_mask\"]\n",
    "\n",
    "# grab the list of images in our dataset directory, then initialize\n",
    "# the list of data (i.e., images) and class images\n",
    "print(\"[INFO] loading images...\")\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DIRECTORY, category)\n",
    "    for img in os.listdir(path):\n",
    "    \timg_path = os.path.join(path, img)\n",
    "    \timage = load_img(img_path, target_size=(224, 224))\n",
    "    \timage = img_to_array(image)\n",
    "    \timage = preprocess_input(image)\n",
    "\n",
    "    \tdata.append(image)\n",
    "    \tlabels.append(category)\n",
    "\n",
    "# perform one-hot encoding on the labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "\ttest_size=0.20, stratify=labels, random_state=42)\n",
    "\n",
    "# construct the training image generator for data augmentation\n",
    "aug = ImageDataGenerator(\n",
    "\trotation_range=20,\n",
    "\tzoom_range=0.15,\n",
    "\twidth_shift_range=0.2,\n",
    "\theight_shift_range=0.2,\n",
    "\tshear_range=0.15,\n",
    "\thorizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")\n",
    "\n",
    "# load the MobileNetV2 network, ensuring the head FC layer sets are\n",
    "# left off\n",
    "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "\tinput_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "# construct the head of the model that will be placed on top of the\n",
    "# the base model\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
    "\n",
    "# place the head FC model on top of the base model (this will become\n",
    "# the actual model we will train)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "# loop over all layers in the base model and freeze them so they will\n",
    "# not be updated during the first training process\n",
    "for layer in baseModel.layers:\n",
    "\tlayer.trainable = False\n",
    "\n",
    "# compile our model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "\n",
    "# train the head of the network\n",
    "print(\"[INFO] training head...\")\n",
    "H = model.fit(\n",
    "\taug.flow(trainX, trainY, batch_size=BS),\n",
    "\tsteps_per_epoch=len(trainX) // BS,\n",
    "\tvalidation_data=(testX, testY),\n",
    "\tvalidation_steps=len(testX) // BS,\n",
    "\tepochs=EPOCHS)\n",
    "\n",
    "# make predictions on the testing set\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predIdxs = model.predict(testX, batch_size=BS)\n",
    "\n",
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "\n",
    "# show a nicely formatted classification report\n",
    "print(classification_report(testY.argmax(axis=1), predIdxs,\n",
    "\ttarget_names=lb.classes_))\n",
    "\n",
    "# serialize the model to disk\n",
    "print(\"[INFO] saving mask detector model...\")\n",
    "model.save(\"mask_detector.model\", save_format=\"h5\")\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "N = EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb09525d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\PIL\\Image.py:962: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "[INFO] compiling model...\n",
      "[INFO] training head...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "102/102 [==============================] - 170s 2s/step - loss: 0.3850 - accuracy: 0.8571 - val_loss: 0.1372 - val_accuracy: 0.9883\n",
      "Epoch 2/15\n",
      "102/102 [==============================] - 156s 2s/step - loss: 0.1432 - accuracy: 0.9644 - val_loss: 0.0708 - val_accuracy: 0.9896\n",
      "Epoch 3/15\n",
      "102/102 [==============================] - 174s 2s/step - loss: 0.0858 - accuracy: 0.9773 - val_loss: 0.0654 - val_accuracy: 0.9831\n",
      "Epoch 4/15\n",
      "102/102 [==============================] - 125s 1s/step - loss: 0.0727 - accuracy: 0.9802 - val_loss: 0.0459 - val_accuracy: 0.9896\n",
      "Epoch 5/15\n",
      "102/102 [==============================] - 120s 1s/step - loss: 0.0631 - accuracy: 0.9829 - val_loss: 0.0418 - val_accuracy: 0.9896\n",
      "Epoch 6/15\n",
      "102/102 [==============================] - 164s 2s/step - loss: 0.0510 - accuracy: 0.9842 - val_loss: 0.0388 - val_accuracy: 0.9896\n",
      "Epoch 7/15\n",
      "102/102 [==============================] - 128s 1s/step - loss: 0.0483 - accuracy: 0.9862 - val_loss: 0.0389 - val_accuracy: 0.9883\n",
      "Epoch 8/15\n",
      "102/102 [==============================] - 132s 1s/step - loss: 0.0405 - accuracy: 0.9885 - val_loss: 0.0360 - val_accuracy: 0.9883\n",
      "Epoch 9/15\n",
      "102/102 [==============================] - 139s 1s/step - loss: 0.0433 - accuracy: 0.9895 - val_loss: 0.0333 - val_accuracy: 0.9883\n",
      "Epoch 10/15\n",
      "102/102 [==============================] - 126s 1s/step - loss: 0.0402 - accuracy: 0.9885 - val_loss: 0.0346 - val_accuracy: 0.9883\n",
      "Epoch 11/15\n",
      "102/102 [==============================] - 132s 1s/step - loss: 0.0372 - accuracy: 0.9881 - val_loss: 0.0305 - val_accuracy: 0.9896\n",
      "Epoch 12/15\n",
      "102/102 [==============================] - 141s 1s/step - loss: 0.0339 - accuracy: 0.9898 - val_loss: 0.0352 - val_accuracy: 0.9896\n",
      "Epoch 13/15\n",
      "102/102 [==============================] - 152s 1s/step - loss: 0.0336 - accuracy: 0.9881 - val_loss: 0.0317 - val_accuracy: 0.9909\n",
      "Epoch 14/15\n",
      "102/102 [==============================] - 140s 1s/step - loss: 0.0350 - accuracy: 0.9888 - val_loss: 0.0367 - val_accuracy: 0.9909\n",
      "Epoch 15/15\n",
      "102/102 [==============================] - 153s 1s/step - loss: 0.0330 - accuracy: 0.9898 - val_loss: 0.0307 - val_accuracy: 0.9909\n",
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   with_mask       0.99      0.99      0.99       383\n",
      "without_mask       0.99      0.99      0.99       384\n",
      "\n",
      "    accuracy                           0.99       767\n",
      "   macro avg       0.99      0.99      0.99       767\n",
      "weighted avg       0.99      0.99      0.99       767\n",
      "\n",
      "[INFO] saving mask detector model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# initialize the initial learning rate, number of epochs to train for,\n",
    "# and batch size\n",
    "INIT_LR = 1e-4\n",
    "EPOCHS = 15\n",
    "BS = 30\n",
    "\n",
    "DIRECTORY = r\"E:\\Face-Mask-Detection\\dataset\"\n",
    "CATEGORIES = [\"with_mask\", \"without_mask\"]\n",
    "\n",
    "# grab the list of images in our dataset directory, then initialize\n",
    "# the list of data (i.e., images) and class images\n",
    "print(\"[INFO] loading images...\")\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DIRECTORY, category)\n",
    "    for img in os.listdir(path):\n",
    "    \timg_path = os.path.join(path, img)\n",
    "    \timage = load_img(img_path, target_size=(224, 224))\n",
    "    \timage = img_to_array(image)\n",
    "    \timage = preprocess_input(image)\n",
    "\n",
    "    \tdata.append(image)\n",
    "    \tlabels.append(category)\n",
    "\n",
    "# perform one-hot encoding on the labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "\ttest_size=0.20, stratify=labels, random_state=42)\n",
    "\n",
    "# construct the training image generator for data augmentation\n",
    "aug = ImageDataGenerator(\n",
    "\trotation_range=20,\n",
    "\tzoom_range=0.15,\n",
    "\twidth_shift_range=0.2,\n",
    "\theight_shift_range=0.2,\n",
    "\tshear_range=0.15,\n",
    "\thorizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")\n",
    "\n",
    "# load the MobileNetV2 network, ensuring the head FC layer sets are\n",
    "# left off\n",
    "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "\tinput_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "# construct the head of the model that will be placed on top of the\n",
    "# the base model\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
    "\n",
    "# place the head FC model on top of the base model (this will become\n",
    "# the actual model we will train)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "# loop over all layers in the base model and freeze them so they will\n",
    "# not be updated during the first training process\n",
    "for layer in baseModel.layers:\n",
    "\tlayer.trainable = False\n",
    "\n",
    "# compile our model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "\n",
    "# train the head of the network\n",
    "print(\"[INFO] training head...\")\n",
    "H = model.fit(\n",
    "\taug.flow(trainX, trainY, batch_size=BS),\n",
    "\tsteps_per_epoch=len(trainX) // BS,\n",
    "\tvalidation_data=(testX, testY),\n",
    "\tvalidation_steps=len(testX) // BS,\n",
    "\tepochs=EPOCHS)\n",
    "\n",
    "# make predictions on the testing set\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predIdxs = model.predict(testX, batch_size=BS)\n",
    "\n",
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "\n",
    "# show a nicely formatted classification report\n",
    "print(classification_report(testY.argmax(axis=1), predIdxs,\n",
    "\ttarget_names=lb.classes_))\n",
    "\n",
    "# serialize the model to disk\n",
    "print(\"[INFO] saving mask detector model...\")\n",
    "model.save(\"mask_detector.model\", save_format=\"h5\")\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "N = EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec000633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\PIL\\Image.py:962: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# initialize the initial learning rate, number of epochs to train for,\n",
    "# and batch size\n",
    "INIT_LR = 1e-4\n",
    "EPOCHS = 2\n",
    "BS = 30\n",
    "\n",
    "DIRECTORY = r\"E:\\Face-Mask-Detection\\dataset\"\n",
    "CATEGORIES = [\"with_mask\", \"without_mask\"]\n",
    "\n",
    "# grab the list of images in our dataset directory, then initialize\n",
    "# the list of data (i.e., images) and class images\n",
    "print(\"[INFO] loading images...\")\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DIRECTORY, category)\n",
    "    for img in os.listdir(path):\n",
    "    \timg_path = os.path.join(path, img)\n",
    "    \timage = load_img(img_path, target_size=(224, 224))\n",
    "    \timage = img_to_array(image)\n",
    "    \timage = preprocess_input(image)\n",
    "\n",
    "    \tdata.append(image)\n",
    "    \tlabels.append(category)\n",
    "\n",
    "# perform one-hot encoding on the labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "\ttest_size=0.20, stratify=labels, random_state=42)\n",
    "\n",
    "# construct the training image generator for data augmentation\n",
    "aug = ImageDataGenerator(\n",
    "\trotation_range=20,\n",
    "\tzoom_range=0.15,\n",
    "\twidth_shift_range=0.2,\n",
    "\theight_shift_range=0.2,\n",
    "\tshear_range=0.15,\n",
    "\thorizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")\n",
    "\n",
    "# load the MobileNetV2 network, ensuring the head FC layer sets are\n",
    "# left off\n",
    "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "\tinput_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "# construct the head of the model that will be placed on top of the\n",
    "# the base model\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
    "\n",
    "# place the head FC model on top of the base model (this will become\n",
    "# the actual model we will train)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "# loop over all layers in the base model and freeze them so they will\n",
    "# not be updated during the first training process\n",
    "for layer in baseModel.layers:\n",
    "\tlayer.trainable = False\n",
    "\n",
    "# compile our model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "\n",
    "# train the head of the network\n",
    "print(\"[INFO] training head...\")\n",
    "H = model.fit(\n",
    "\taug.flow(trainX, trainY, batch_size=BS),\n",
    "\tsteps_per_epoch=len(trainX) // BS,\n",
    "\tvalidation_data=(testX, testY),\n",
    "\tvalidation_steps=len(testX) // BS,\n",
    "\tepochs=EPOCHS)\n",
    "\n",
    "# make predictions on the testing set\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predIdxs = model.predict(testX, batch_size=BS)\n",
    "\n",
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "\n",
    "# show a nicely formatted classification report\n",
    "print(classification_report(testY.argmax(axis=1), predIdxs,\n",
    "\ttarget_names=lb.classes_))\n",
    "\n",
    "# serialize the model to disk\n",
    "print(\"[INFO] saving mask detector model...\")\n",
    "model.save(\"mask_detector.model\", save_format=\"h5\")\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "N = EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36db3e32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
